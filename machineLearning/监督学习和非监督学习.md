1.supervised learning : 
    (1)give the input and output, or question and right answer, produce the algorithm
    (2)the main form: regression and classification.
    (3)regression: the answer haven't specific number range,like house price releate with size
    (4)classification: the answer have specific categories, like tumor benight and malignant releate with size and patient age.
2.unsupervised learning:
    (1)give dataset,don't give right answer,machine found the similar data together in dataset, and produce the algorith.Like the customer group class
    (2)cluster algorithm
3.standard notation
    supervised learning: a part of (x,y) data refer single data example. x and y have superscript (i) , the (i) refer each row data example.
4.linear regresion 
    f(x)=wx + b
    the value of expression is called y-hat, it is predict value, not the truth value.
5.gradient descent
    (1)the best model is the y-hat which most close truth y. use J(w,b) representation.
    J(w,b) = squaries erro (y-hat^i minus y^i),and the sum of all examples.
    as small as possible for J(w,b),the minumize of J, the w ,b is best value.
    (2)w & b ,are litera,simultaneous update,expression is
    w = w - a* c/cz*J(w,b)
    b = b - a* c/cz*J(w,b)
6.multiple feature
    called vectorization, multiple linear regression,like:
        f_w,b(x)=w_1*x_1 + w_2*x_2 + w_3*x_3 + …… +w_n*x_n + b
        define :
        x_1^1 reference in sample,the fisrt row and fist feature value
        x_1^2 reference in sample,the second row and fist feature value
        x_2^3 reference in sample,the third row and second feature value
    simply expression,a really simplify trick，called vectorization
        f_w-arrow,b(x-arrow)=w-arrow * x-arrow +b
7.vectorization
    use vectorization code in python
    import NumPy as np
    f = np.dot(w,x)